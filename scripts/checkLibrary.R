### LANDFIRE Project
### APEX RMS - Shreeram Senthivasan
### November 2020
### The function defined in this script is used to perform a collection of checks
### on the library and scenarios generated by the two functions in
### `scripts/buildSsimLibrary.R`

checkLibrary <- function(libraryName, projectName, runTags) {
  # Load Library and Project ---------------------------------------------------
  ssimSession <- session(ssimDir)
  mylibrary <- ssimLibrary(libraryName, session = ssimSession)
  myproject <- rsyncrosim::project(mylibrary, projectName)
  myscenario <- scenario(myproject, "template")
  
  # Load data sheets needed for checks common to all scenarios
  rules <- datasheet(myscenario, "stsim_Transition") %>%
    select(-Probability, StateClassIDDest)
  
  stateClasses <- datasheet(myproject, "stsim_StateClass") %>%
    pull(ID)
  
  # Check for duplicate rules --------------------------------------------------
  
  # Are there any states with duplicate rules?
  # - within each EVT, mapzone, and transition type, there should only be one rule
  #   (ie. one row) for each state class
  numDuplicateRules <-
    rules %>%
    group_by(StratumIDSource, SecondaryStratumID, TransitionTypeID, StateClassIDSource) %>%
    summarise(unique = (n() == 1)) %>%
    filter(!unique) %>%
    nrow
  
  if(numDuplicateRules > 0)
    stop("Found duplicate rules for one or more states! Please check the `probabilisticTransitions` data.frame!")
  
  # Check for invalid state classes --------------------------------------------
  
  # Are there mixed life form or other invalid state classes?
  # - Mixed life form states can be identified by vegetation cover (x state) labels
  #   that don't match their vegetation height (y state) labels
  allowedStates <- read_csv(allowedStatesPath) %>%
    mutate(ID = EVC * 1000 + EVH) %>%
    pull(ID)
  
  numInvalidStates <-
   !(stateClasses %in% allowedStates) %>%
    sum
  
  if(numInvalidStates != 0)
    stop("Found invalid state classes! Please check the transition table non-spatial input!")
  
  # Check for missing rules ---------------------------------------------------
  
  # Are there combinations of EVC, EVH, EVT, MZ, and VDIST present in the rasters
  # for which there are no rules?
  
  # Note that this requires the 'data/clean' subdirectory to still be intact
  
  ## +Generate list of rules present -------------------------------------------
  
  # Read in the rules as codes and convert each combination of EVC, EVH, EVT,
  # MZ, and VDIST into a unique code
  ruleCodes <- read_xlsx(transitionTablePath, col_types = "text") %>% # Read in the whole set of rules as text
    select(EVC = EVCB, EVH = EVHB, EVT = EVT7B, MZ, VDIST) %>%
    unique %>%
    map2_dfc(           # Recall that the table is read in as text. Here we pad the columns so they are uniform widths
      c(3,3,4,2,3),     # Widths to pad each of the columns to. All are three except EVT (4), and MZ (2)
      str_pad,
      side = "left",
      pad = "0"
    ) %>%
    pmap_chr(str_c) %>% # This pastes the columns together to make a unique code for each row
    as.numeric

  # Begin parallel processing across scenarios
  plan(multisession, workers = nThreads)

  allMissingRules <- future_map_dfr( # *_dfr indicates the results should be combined using `bind_rows()`
    runTags,
    listMissingRules,
    ruleCodes = ruleCodes
  )

  # Return to sequential operation
  plan(sequential)

  write_csv(missingRules, paste0("library/", runLibrary, " Missing Rules.csv"))
}

# Function to find missing rules from a Map Zone using a list of unqiue rule codes
# - See `checkLibrary()` for details on the rule code format
listMissingRules <- function(runTag, ruleCodes) {
  ## +Generate spatial data paths ----------------------------------------------

  # Directory to load cleaned rasters from for the given scenario
  cleanRasterDirectory <- paste0(getwd(), "/data/clean/", runTag, "/")
  
  # Rasters needed to calculate codes
  stateClassRasterPath <- paste0(cleanRasterDirectory, "StateClass.tif")
  evtRasterPath <- paste0(cleanRasterDirectory, "EVT.tif")
  mapzoneRasterPath <- paste0(cleanRasterDirectory, "MapZone.tif")
  vdistRasterPath <- paste0(cleanRasterDirectory, "VDIST.tif")
  
  ## +Find codes presen in Map Zone --------------------------------------------
  
  mapzoneCodes <- getUniqueCodes(
    state = raster(stateClassRasterPath),
    evt =   raster(evtRasterPath),
    mz =    raster(mapzoneRasterPath),
    vdist = raster(vdistRasterPath)
  )
  
  ## +Generate human-readable table of missing rules ---------------------------
  missingRules <- 
    tibble(code = setdiff(mapzoneCodes, ruleCodes)) %>%
    mutate(code = str_pad(code, 15, "left", "0")) %>% # Make sure all codes are the same length before separating into columns by position
    separate(code,
             into = c("EVC", "EVH", "EVT", "MZ", "VDIST"),
             sep = c(3,6,10,12)) %>%
    mutate_all(as.numeric) %>%
    # Use look up tables to add names from the codes
    left_join(read_xlsx(evcTablePath) %>% select(EVC = VALUE, EVC_NAME = CLASSNAMES)) %>%
    left_join(read_xlsx(evhTablePath) %>% select(EVH = VALUE, EVH_NAME = CLASSNAMES)) %>%
    left_join(read_xlsx(evtColorTablePath) %>% select(EVT = VALUE, EVT_NAME)) %>%
    left_join(read_xlsx(vdistTablePath) %>% select(VDIST = value, d_type, d_severity, d_time)) %>%
    unite(VDIST_NAME, d_type, d_severity, d_time, sep = " - ")
  
  return(missingRules)
}

# Function to generate a list  of unique rule codes present in a set of large rasters
# - Note that rasters are assumed to have identical extents, resolutions, etc.
getUniqueCodes <- function(state, evt, mz, vdist) {
  # Choose number of blocks to split rasters into when processing to limit memory
  blockInfo <- blockSize(state)
  
  # Calculate unique values in each block
  map(
    seq(blockInfo$n),
    function(i) {
      unique(
        getValuesBlock(state,
                       row   = blockInfo$row[i],
                       nrows = blockInfo$nrows[i]) * 1e9 +
        getValuesBlock(evt,
                       row   = blockInfo$row[i],
                       nrows = blockInfo$nrows[i]) * 1e5 +
        getValuesBlock(mz,
                         row   = blockInfo$row[i],
                         nrows = blockInfo$nrows[i]) * 1e3 +
        getValuesBlock(vdist,
                         row   = blockInfo$row[i],
                         nrows = blockInfo$nrows[i])
      )
    }) %>%
    # Consolidate values from each block
    flatten_dbl %>%
    unique() %>%
    # Exclude NA and any code ending in 000 (no disturbance)
    `[`(!is.na(.)) %>%
    `[`(!. %% 1000 == 0) %>% # Ending in 000 is equivalent to being divisible by 1000
    return
}
